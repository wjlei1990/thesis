% Encoding: UTF-8
@article{Katz2016,
abstract = {Computer scientists who work on tools and systems to support eScience (a variety of parallel and distributed) applications usually use actual applications to prove that their systems will benefit science and engineering (e.g., improve application performance). Accessing and building the applications and necessary data sets can be difficult because of policy or technical issues, and it can be difficult to modify the characteristics of the applications to understand corner cases in the system design. In this paper, we present the Application Skeleton, a simple yet powerful tool to build synthetic applications that represent real applications, with runtime and I/O close to those of the real applications. This allows computer scientists to focus on the system they are building; they can work with the simpler skeleton applications and be sure that their work will also be applicable to the real applications. In addition, skeleton applications support simple reproducible system experiments since they are represented by a compact set of parameters. Our Application Skeleton tool (available as open source at https://github.com/applicationskeleton/Skeleton) currently can create easy-to-access, easy-to-build, and easy-to-run bag-of-task, (iterative) map-reduce, and (iterative) multistage workflow applications. The tasks can be serial, parallel, or a mix of both. The parameters to represent the tasks can either be discovered through a manual profiling of the applications or through an automated method. We select three representative applications (Montage, BLAST, CyberShake Postprocessing), then describe and generate skeleton applications for each. We show that the skeleton applications have identical (or close) performance to that of the real applications. We then show examples of using skeleton applications to verify system optimizations such as data caching, I/O tuning, and task scheduling, as well as the system resilience mechanism, in some cases modifying the skeleton applications to emphasize some characteristic, and thus show that using skeleton applications simplifies the process of designing, implementing, and testing these optimizations.},
author = {Katz, Daniel S. and Merzky, Andre and Zhang, Zhao and Jha, Shantenu},
doi = {10.1016/j.future.2015.10.001},
file = {:Users/ml15/Google Drive/papers/workflow{\_}management/2015{\_}Katz{\_}skeleton{\_}draft.pdf:pdf},
issn = {0167739X},
journal = {Future Generation Computer Systems},
keywords = {computational science},
month = {jun},
pages = {114--124},
title = {{Application skeletons: Construction and use in eScience}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167739X15003143},
volume = {59},
year = {2016}
}
@article{Maechling2005,
author = {Maechling, Philip and Mehta, Gaurang and Mendenhall, Brian and Russ, Thomas and Singh, Gurmeet and Spraragen, Marc and Staples, Garrick and Vahi, Karan and Chalupsky, Hans and Dougherty, Maureen and Deelman, Ewa and Gil, Yolanda and Gullapalli, Sridhar and Gupta, Vipin and Kesselman, Carl and Kim, Jihic},
doi = {10.1145/1084805.1084811},
file = {:Users/ml15/Library/Application Support/Mendeley Desktop/Downloaded/Maechling et al. - 2005 - Simplifying construction of complex workflows for non-expert users of the Southern California Earthquake Cente.pdf:pdf},
issn = {01635808},
journal = {ACM SIGMOD Record},
keywords = {data management,grid,intelligent assistant,meta-scheduler,metadata,pegasus,scheduling,seismic hazard analysis,semantic web,workflow},
month = {sep},
number = {3},
pages = {24},
publisher = {ACM},
title = {{Simplifying construction of complex workflows for non-expert users of the Southern California Earthquake Center Community Modeling Environment}},
url = {http://portal.acm.org/citation.cfm?doid=1084805.1084811},
volume = {34},
year = {2005}
}
@article{Deelman2006,
abstract = {In this paper we discuss several challenges associated scientific workflow design and management in distributed, heterogeneous environments. Based on our prior work with a number of scientific applications, we describe the workflow lifecycle and examine our experiences and the challenges ahead as they pertain to the user experience, planning the workflow execution and managing the execution itself.},
author = {Deelman, Ewa and Gil, Yolanda},
doi = {10.1109/E-SCIENCE.2006.261077},
file = {:Users/ml15/Google Drive/papers/workflow{\_}management/wf{\_}geophysics/2006{\_}Deelman{\_}Cybershake.pdf:pdf},
isbn = {0769527345},
journal = {e-Science 2006 - Second IEEE International Conference on e-Science and Grid Computing},
title = {{Managing large-scale scientific workflows in distributed environments: Experiences and challenges}},
year = {2006}
}
@article{Callaghan2010,
author = {Callaghan, Scott and Deelman, Ewa and Gunter, Dan and Juve, Gideon and Maechling, Philip and Brooks, Christopher and Vahi, Karan and Milner, Kevin and Graves, Robert and Field, Edward and Okaya, David and Jordan, Thomas},
doi = {10.1016/j.jcss.2009.11.005},
file = {:Users/ml15/Google Drive/papers/workflow{\_}management/wf{\_}geophysics/2010{\_}Callaghan{\_}Cybershake.pdf:pdf},
issn = {00220000},
journal = {Journal of Computer and System Sciences},
keywords = {Distributed applications,Scientific workflows,Workflow scalability},
number = {6},
pages = {428--446},
publisher = {Elsevier Inc.},
title = {{Scaling up workflow-based applications}},
url = {http://dx.doi.org/10.1016/j.jcss.2009.11.005},
volume = {76},
year = {2010}
}
@article{Graves2011,
author = {Graves, Robert and Jordan, Thomas H. and Callaghan, Scott and Deelman, Ewa and Field, Edward and Juve, Gideon and Kesselman, Carl and Maechling, Philip and Mehta, Gaurang and Milner, Kevin and Okaya, David and Small, Patrick and Vahi, Karan},
doi = {10.1007/s00024-010-0161-6},
file = {:Users/ml15/Google Drive/papers/workflow{\_}management/wf{\_}geophysics/2011{\_}Graves{\_}Cybershake.pdf:pdf},
issn = {00334553},
journal = {Pure and Applied Geophysics},
keywords = {3D basin response,Physics-based earthquake simulation,rupture directivity,seismic hazard},
number = {3-4},
pages = {367--381},
title = {{CyberShake: A Physics-Based Seismic Hazard Model for Southern California}},
volume = {168},
year = {2011}
}
@article{Hemert2008,
annote = {General paper.Also talk about business workflows.},
author = {Hemert, A.B.a.J.v.},
doi = {10.1145/2213836.2213899},
file = {:Users/ml15/Google Drive/papers/workflow{\_}management/2007{\_}Barker{\_}WfSurvey.pdf:pdf},
isbn = {3-540-68105-1, 978-3-540-68105-2},
journal = {Parallel Processing and Applied Mathematics},
keywords = {scientific workflow},
pages = {746--753},
title = {{Scientific Workflow: A Survey and Research Directions}},
year = {2008}
}
@article{Deelman201517,
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Deelman, Ewa and Vahi, Karan and Juve, Gideon and Rynge, Mats and Callaghan, Scott and Maechling, Philip J. and Mayani, Rajiv and Chen, Weiwei and {Ferreira da Silva}, Rafael and Livny, Miron and Wenger, Kent},
doi = {http://dx.doi.org/10.1016/j.future.2014.10.008},
eprint = {arXiv:1011.1669v3},
file = {:Users/ml15/Google Drive/papers/workflow{\_}management/2014{\_}Deelman{\_}Pegasus.pdf:pdf},
isbn = {9788578110796},
issn = {0167-739X},
journal = {Future Generation Computer Systems},
keywords = {Pegasus,Scientific workflows,Workflow management system,icle},
pages = {17--35},
pmid = {25246403},
title = {{Pegasus, a workflow management system for science automation}},
url = {http://www.sciencedirect.com/science/article/pii/S0167739X14002015},
volume = {46},
year = {2015}
}
@article{Ludascher2009,
author = {Ludascher, Bertram and Weske, Mathias and McPhillips, Timothy and Bowers, Shawn},
doi = {10.1007/978-3-642-03848-8},
file = {:Users/ml15/Google Drive/papers/workflow{\_}management/2009{\_}Ludascher{\_}ScientificBusinessWf.pdf:pdf},
isbn = {978-3-642-03847-1},
journal = {Business Process Managment},
pages = {31--47},
title = {{Scientific Workflows: Business as Usual?}},
url = {http://www.springerlink.com/index/10.1007/978-3-642-03848-8},
volume = {5701},
year = {2009}
}
@article{Yu2005,
author = {Yu, Jia and Buyya, Rajkumar},
doi = {10.1145/1084805.1084814},
file = {:Users/ml15/Google Drive/papers/workflow{\_}management/2005{\_}Buyya{\_}Wf{\_}taxonomy.pdf:pdf},
isbn = {1084805108},
issn = {01635808},
journal = {ACM SIGMOD Record},
keywords = {Grid,Scientific workflows,Taxonomy},
pages = {44--49},
title = {{A taxonomy of scientific workflow systems for grid computing}},
url = {http://dl.acm.org/citation.cfm?doid=1084805.1084814},
year = {2005}
}
@article{Curcin2008,
author = {Curcin, V and Ghanem, M},
doi = {10.1109/CIBEC.2008.4786077},
file = {:Users/ml15/Google Drive/papers/workflow{\_}management/2008{\_}Curcin{\_}oneSize.pdf:pdf},
isbn = {978-1-4244-2694-2},
issn = {1424426944},
journal = {2008 Cairo Int. Biomed. Eng. Conf.},
keywords = {Bioinformatics,Business,Control systems,Data analysis,Data mining,Distributed computing,EBI Web services,Educational institutions,Grid computing,Testing,Web services,bioinformatics,control flow,data flow,distributed databases,remote computational resources,remote distributed scientific data sets,scientific workflow systems,workflow systems},
pages = {1--9},
title = {{Scientific workflow systems - can one size fit all?}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4786077},
year = {2008}
}
@inproceedings{Lefebvre2014,
author = {Lefebvre, Matthieu and Bozdag, Ebru and Calandra, Henri and Hill, Judy and Podhorszki, Norbert and Pugmire, Dave and Tromp, Jeroen},
booktitle = {4th SC Workshop on Petascale Data Analytics},
file = {:Users/ml15/Google Drive/papers/MyPublications/2014{\_}Lefebvre{\_}Workflow.pdf:pdf},
title = {{A Data Centric View of Large-Scale Seismic Imaging Workflows}},
url = {http://sc13.supercomputing.org/sites/default/files/WorkshopsArchive/pdfs/wp121s1.pdf},
year = {2014}
}
@article{Zhao2007,
abstract = {We present Swift, a system that combines a novel scripting language called SwiftScript with a powerful runtime system based on CoG Karajan, Falkon, and Globus to allow for the concise specification, and reliable and efficient execution, of large loosely coupled computations. Swift adopts and adapts ideas first explored in the GriPhyN virtual data system, improving on that system in many regards. We describe the SwiftScript language and its use of XDTM to describe the logical structure of complex file system structures. We also present the Swift runtime system and its use of CoG Karajan, Falkon, and Globus services to dispatch and manage the execution of many tasks in parallel and grid environments. We describe application experiences and performance experiments that quantify the cost of Swift operations.},
author = {Zhao, Yong and Hategan, Mihael and Clifford, Ben and Foster, Ian and {Von Laszewski}, Gregor and Nefedova, Veronika and Raicu, Ioan and Stef-Praun, Tiberiu and Wilde, Michael},
doi = {10.1109/SERVICES.2007.63},
file = {:Users/ml15/Google Drive/papers/workflow{\_}management/2007{\_}Zhao{\_}Swift.pdf:pdf},
isbn = {0769529267},
journal = {2007 IEEE Congress on Services Services 2007},
number = {Services},
pages = {199--206},
publisher = {Ieee},
title = {{Swift: Fast, Reliable, Loosely Coupled Parallel Computation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4278797},
volume = {0},
year = {2007}
}
@article{Wilde2009,
author = {Wilde, Michael and Foster, Ian and Iskra, Kamil and Beckman, Pete and Zhang, Zhao and Espinosa, Allan and Hategan, Mihael and Clifford, Ben and Raicu, Ioan},
doi = {10.1109/MC.2009.365},
issn = {00189162},
journal = {Computer},
number = {11},
pages = {50--60},
publisher = {IEEE Computer Society},
title = {{Parallel Scripting for Applications at the Petascale and Beyond}},
url = {http://doi.ieeecomputersociety.org/10.1109/MC.2009.365},
volume = {42},
year = {2009}
}
@techreport{ogf-gfd-90,
author = {Goodale, Tom and Jha, Shantenu and Kaiser, Hartmut and Kielmann, Thilo and Kleijer, Pascal and Merzky, Andre and Shalf, John and Smith, Christopher},
institution = {Open Grid Forum},
title = {{A Simple API for Grid Applications (SAGA)}},
type = {OGF Recommendation, GFD.90},
url = {http://ogf.org/documents/GFD.90.pdf},
year = {2007}
}

@Misc{Turilli2016,
  author = {Turilli, Matteo and Santcroos, Mark and Jha, Shantenu},
  title  = {{A Comprehensive Perspective on Pilot-Jobs}},
  year   = {2016},
  annote = {(under review)\url{http://arxiv.org/abs/1508.04180}},
}
@article{Luckow2015,
archivePrefix = {arXiv},
arxivId = {arXiv:1501.05041v1},
author = {Luckow, A and Mantha, P and Jha, S},
eprint = {arXiv:1501.05041v1},
file = {:Users/ml15/Google Drive/papers/workflow{\_}management/2015-hpdc{\_}draft.pdf:pdf},
journal = {arXiv preprint arXiv:1501.05041},
title = {{Pilot-Abstraction: A Valid Abstraction for Data-Intensive Applications on HPC, Hadoop and Cloud Infrastructures?}},
url = {http://arxiv.org/abs/1501.05041},
year = {2015}
}
@inproceedings{Fomel2007,
author = {Fomel, Sergey and Hennenfent, G.},
booktitle = {2007 IEEE International Conference on Acoustics, Speech and Signal Processing - ICASSP '07},
doi = {10.1109/ICASSP.2007.367305},
file = {:Users/ml15/Google Drive/papers/workflow{\_}management/wf{\_}geophysics/2007{\_}fomel{\_}scons.pdf:pdf},
pages = {1520--6149},
title = {{Reproducible Computational Experiments using Scons}},
year = {2007}
}
@article{Morgan2014,
abstract = {Roundtable participants identified ways of making computational research details readily available, which is a crucial step in addressing the current credibility crisis.},
author = {Morgan, Martin},
doi = {10.1109/MCSE.2010.113},
file = {:Users/ml15/Google Drive/papers/workflow{\_}management/wf{\_}geophysics/2009{\_}Fomel{\_}reproducible.pdf:pdf},
isbn = {1521-9615},
issn = {1521-9615},
journal = {Computing in Science {\&} Engineering},
keywords = {Computational science,code sharing,data sharing,reproducible research,scientific integrity,scientific method},
number = {5},
pages = {2014--2015},
title = {{Reproducible Research}},
volume = {12},
year = {2014}
}
@article{Zhang2013,
author = {Zhang, Xiaofeng and Chen, Po and Pullammanappallil, Satish},
doi = {10.1007/s11589-013-0032-1},
file = {:Users/ml15/Google Drive/papers/geophysics/2013{\_}Zhang{\_}inversion{\_}workflow.pdf:pdf},
issn = {16744519},
journal = {Earthquake Science},
keywords = {Adjoint tomography,Kepler,Scientific workflow,Seismic inversion},
number = {5},
pages = {331--339},
title = {{Automating adjoint wave-equation travel-time tomography using scientific workflow}},
volume = {26},
year = {2013}
}
@article{Fomel2013,
author = {Fomel, Sergey and Sava, Paul and Vlad, Ioan and Liu, Yang and Bashkardin, Vladimir},
doi = {http://dx.doi.org/10.5334/jors.ag},
file = {:Users/ml15/Google Drive/papers/workflow{\_}management/wf{\_}geophysics/2013{\_}fomel{\_}magadascar.pdf:pdf},
issn = {2049-9647},
journal = {Journal of Open Research Software},
keywords = {data analysis,geophysics,python,reproducibility,seismology},
number = {1},
pages = {e8},
title = {{Madagascar: open-source software project for multidimensional data analysis and reproducible computational experiments}},
url = {http://openresearchsoftware.metajnl.com/article/view/jors.ag/20},
volume = {1},
year = {2013}
}

@Article{condor-practice,
  author  = {Douglas Thain and Todd Tannenbaum and Miron Livny},
  title   = {Distributed computing in practice: the Condor experience.},
  journal = {Concurrency - Practice and Experience},
  year    = {2005},
  volume  = {17},
  number  = {2-4},
  pages   = {323-356},
}

@InProceedings{Altintas2004,
  author    = {Altintas, Ilkay and Berkley, Chad and Jaeger, Efrat and Jones, Matthew and Ludascher, Bertram and Mock, Steve},
  title     = {Kepler: An Extensible System for Design and Execution of Scientific Workflows},
  booktitle = {Proceedings of the 16th International Conference on Scientific and Statistical Database Management},
  year      = {2004},
  series    = {SSDBM '04},
  pages     = {423--},
  address   = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  acmid     = {1007097},
  doi       = {10.1109/SSDBM.2004.44},
  isbn      = {0-7695-2146-0},
  url       = {http://dx.doi.org/10.1109/SSDBM.2004.44},
}

@Article{Wolstencroft2013,
  author    = {Wolstencroft, Katherine and Haines, Robert and Fellows, Donal and Williams, Alan and Withers, David and Owen, Stuart and Soiland-Reyes, Stian and Dunlop, Ian and Nenadic, Aleksandra and Fisher, Paul and Bhagat, Jiten and Belhajjame, Khalid and Bacall, Finn and Hardisty, Alex and Nieva de la Hidalga, Abraham and Balcazar Vargas, Maria P. and Sufi, Shoaib and Goble, Carole},
  title     = {{The Taverna workflow suite: designing and executing workflows of Web Services on the desktop, web or in the cloud}},
  journal   = {Nucleic Acids Research},
  year      = {2013},
  volume    = {41},
  number    = {Web Server issue},
  pages     = {gkt328--W561},
  month     = may,
  day       = {2},
  doi       = {10.1093/nar/gkt328},
  issn      = {1362-4962},
  keywords  = {bioinformatics, informatics, myexperiment, taverna, workflow},
  pmcid     = {PMC3692062},
  pmid      = {23640334},
  posted-at = {2013-05-06 09:27:44},
  publisher = {Oxford University Press},
  url       = {http://dx.doi.org/10.1093/nar/gkt328},
}

@InBook{Taylor2007,
  pages     = {320--339},
  title     = {The Triana Workflow Environment: Architecture and Applications},
  publisher = {Springer London},
  year      = {2007},
  author    = {Taylor, Ian and Shields, Matthew and Wang, Ian and Harrison, Andrew},
  editor    = {Taylor, Ian J. and Deelman, Ewa and Gannon, Dennis B. and Shields, Matthew},
  address   = {London},
  booktitle = {Workflows for e-Science: Scientific Workflows for Grids},
  doi       = {10.1007/978-1-84628-757-2_20},
  isbn      = {978-1-84628-757-2},
  url       = {http://dx.doi.org/10.1007/978-1-84628-757-2_20},
}

@InProceedings{Cronsioe2013,
  author    = {J. Cronsioe and B. Videau and V. Marangozova-Martin},
  title     = {BOAST: Bringing Optimization through Automatic Source-to-Source Transformations},
  booktitle = {Embedded Multicore Socs (MCSoC), 2013 IEEE 7th International Symposium on},
  year      = {2013},
  pages     = {129-134},
  month     = {Sept},
  doi       = {10.1109/MCSoC.2013.12},
  keywords  = {multiprocessing systems;parallel processing;power aware computing;BOAST;BigDFT scientific application;Tibidado high-performance machine;automatic source-to-source transformations;convolution operators;loop structure optimization;loop unrolling;low-energy-consumption machine;multicore platform;performance configuration;performance gain;Benchmark testing;Computer architecture;Convolution;Hardware;Optimization;Program processors;Radiation detectors;Auto-tuning;High performance computing;Optimization;Source to Source transformations},
}

@Comment{jabref-meta: databaseType:bibtex;}
